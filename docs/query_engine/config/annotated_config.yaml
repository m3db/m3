listenAddress:
  type: "config"
  value: "0.0.0.0:7201"

# metrics configuration
metrics:
  scope:
    prefix: "coordinator"
  prometheus:
    handlerPath: /metrics
    listenAddress: 0.0.0.0:7203 # until https://github.com/m3db/m3/issues/682 is resolved
  sanitization: prometheus
  samplingRate: 1.0
  extended: none

clusters:
  - namespaces:
      - namespace: default
        type: unaggregated
        retention: 48h
    client:
      config:
        service:
          env: default_env
          zone: embedded
          service: m3db
          cacheDir: /var/lib/m3kv
          etcdClusters:
            - zone: embedded
              endpoints:
                - 127.0.0.1:2379
        seedNodes:
          initialCluster:
            - hostID: m3db_local
              endpoint: http://127.0.0.1:2380
      writeConsistencyLevel: majority
      readConsistencyLevel: unstrict_majority
      writeTimeout: <duration>
      # fetchTimeout defines the fetch timeout for any given query.
      # The default is 30s and the max is 5m.
      fetchTimeout: <duration>
      connectTimeout: 20s
      writeRetry:
        initialBackoff: 500ms
        backoffFactor: 3
        maxRetries: 2
        jitter: true
      fetchRetry:
        initialBackoff: 500ms
        backoffFactor: 2
        maxRetries: 3
        jitter: true
      backgroundHealthCheckFailLimit: 4
      backgroundHealthCheckFailThrottleFactor: 0.5

readWorkerPoolPolicy:
  grow: <bool>
  size: <int>

writeWorkerPoolPolicy:
  grow: <bool>
  size: <int>

tagOptions:
  # See here for more information: http://m3db.github.io/m3/how_to/query/#id-generation
  idScheme: <id_scheme>

# lookbackDuration defines, at each step, how long we lookback until we see a non-NaN value.
# If not set, we default to 5m, which matches Prometheus.
lookbackDuration: <duration>

# ResultOptions are the result options for query.
resultOptions:
  #	KeepNans keeps NaNs before returning query results.
  # The default is false, which matches Prometheus
  keepNans: <bool>

# Enables local jaeger tracing. See https://www.jaegertracing.io/docs/1.9/getting-started/
# for quick local setup (which this config will send data to).
tracing:
  backend: jaeger

# limits place logical limitations on the resource usage of the query service,
# expressed primarily in the number of datapoints used by a query.
limits:
  # perQuery limits apply to each individual call to the query service, and
  # are evaluated in isolation.
  perQuery:
    # maxFetchedDatapoints limits the number of datapoints used in the
    # course of a query. They are evaluated across all time series in the query;
    # roughly, the number of datapoints for a
    # query = num_series * resolution * length_of_query
    # TODO (andrewmains12): the numbers here are not representative of
    # production worloads; provide guidance on tweaking these.
    maxFetchedDatapoints: 100000 # 100k

  # global limits are calculated across queries, and limit the resources used
  # by *all* in-flight queries
  global:
    # maxFetchedDatapoints limits the total number of datapoints used
    # by all running queries at any given time. See limits.perQuery.maxFetchedDatapoints
    # for a discussion on how these are calculated.
    # TODO (andrewmains12): the numbers here are not representative of
    # production worloads; provide guidance on tweaking these.
    maxFetchedDatapoints: 1000000 # 1 million